{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import sys\n",
    "from pandas import DataFrame\n",
    "from sklearn.utils import shuffle\n",
    "from collections import OrderedDict\n",
    "import hashlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Extractor import FeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "APACHE_ACCESS_LOG_PATTERN = '^(\\S+) (\\S+) (\\S+) (\\S+) (\\S+) (.*)'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo = open(\"abc.txt\", \"r\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fo = fo.read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'081109 203518 143 INFO dfs.DataNode$DataXceiver: Receiving block blk_-1608999687919862906 src: /10.250.19.102:54106 dest: /10.250.19.102:50010\\r\\n081109 203518 35 INFO dfs.FSNamesystem: BLOCK* NameSystem.allocateBlock: /mnt/hadoop/mapred/system/job_200811092030_0001/job.jar. blk_-1608999687919862906\\r\\n081109 203519 143 INFO dfs.DataNode$DataXceiver: Receiving block blk_-1608999687919862906 src: /10.250.10.6:40524 dest: /10.250.10.6:50010\\r\\n081109 203519 145 INFO dfs.DataNode$DataXceiver: Receiving block blk_-1608999687919862906 src: /10.250.14.224:42420 dest: /10.250.14.224:50010\\r\\n081109 203519 145 INFO dfs.DataNode$PacketResponder: PacketResponder 1 for block blk_-1608999687919862906 terminating\\r\\n081109 203519 145 INFO dfs.DataNode$PacketResponder: PacketResponder 2 for block blk_-1608999687919862906 terminating\\r\\n\\r\\n\\r\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_hdfs_file(file_ab, APACHE_ACCESS_LOG_PATTERN):\n",
    "    ab = []\n",
    "    file_line = file_ab.split(\"\\n\")\n",
    "    for line in range(len(file_line)):\n",
    "        match = re.findall(APACHE_ACCESS_LOG_PATTERN,file_line[line])\n",
    "        for mat in range(len(match)):\n",
    "            bd = re.sub(\"[\\d.-]+\", \"<*>\", match[mat][5])\n",
    "            eventid = hashlib.md5(' '.join(bd).encode('utf-8')).hexdigest()[0:8]\n",
    "            ab.append([match[mat][0],match[mat][1],match[mat][2],match[mat][3],match[mat][4],match[mat][5],bd, eventid] )\n",
    "    return ab \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'081109',\n",
       "  u'203518',\n",
       "  u'143',\n",
       "  u'INFO',\n",
       "  u'dfs.DataNode$DataXceiver:',\n",
       "  u'Receiving block blk_-1608999687919862906 src: /10.250.19.102:54106 dest: /10.250.19.102:50010\\r',\n",
       "  u'Receiving block blk_<*> src: /<*>:<*> dest: /<*>:<*>\\r',\n",
       "  '91205f34'],\n",
       " [u'081109',\n",
       "  u'203518',\n",
       "  u'35',\n",
       "  u'INFO',\n",
       "  u'dfs.FSNamesystem:',\n",
       "  u'BLOCK* NameSystem.allocateBlock: /mnt/hadoop/mapred/system/job_200811092030_0001/job.jar. blk_-1608999687919862906\\r',\n",
       "  u'BLOCK* NameSystem<*>allocateBlock: /mnt/hadoop/mapred/system/job_<*>_<*>/job<*>jar<*> blk_<*>\\r',\n",
       "  'c164f67d'],\n",
       " [u'081109',\n",
       "  u'203519',\n",
       "  u'143',\n",
       "  u'INFO',\n",
       "  u'dfs.DataNode$DataXceiver:',\n",
       "  u'Receiving block blk_-1608999687919862906 src: /10.250.10.6:40524 dest: /10.250.10.6:50010\\r',\n",
       "  u'Receiving block blk_<*> src: /<*>:<*> dest: /<*>:<*>\\r',\n",
       "  '91205f34'],\n",
       " [u'081109',\n",
       "  u'203519',\n",
       "  u'145',\n",
       "  u'INFO',\n",
       "  u'dfs.DataNode$DataXceiver:',\n",
       "  u'Receiving block blk_-1608999687919862906 src: /10.250.14.224:42420 dest: /10.250.14.224:50010\\r',\n",
       "  u'Receiving block blk_<*> src: /<*>:<*> dest: /<*>:<*>\\r',\n",
       "  '91205f34'],\n",
       " [u'081109',\n",
       "  u'203519',\n",
       "  u'145',\n",
       "  u'INFO',\n",
       "  u'dfs.DataNode$PacketResponder:',\n",
       "  u'PacketResponder 1 for block blk_-1608999687919862906 terminating\\r',\n",
       "  u'PacketResponder <*> for block blk_<*> terminating\\r',\n",
       "  '6238d96c'],\n",
       " [u'081109',\n",
       "  u'203519',\n",
       "  u'145',\n",
       "  u'INFO',\n",
       "  u'dfs.DataNode$PacketResponder:',\n",
       "  u'PacketResponder 2 for block blk_-1608999687919862906 terminating\\r',\n",
       "  u'PacketResponder <*> for block blk_<*> terminating\\r',\n",
       "  '6238d96c']]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_hdfs_file(fo, APACHE_ACCESS_LOG_PATTERN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse_hdfs_file(fo,APACHE_ACCESS_LOG_PATTERN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fo = open(\"HDFS.log\", \"r\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dta = parse_hdfs_file(fo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.DataFrame(dta,columns=[\"Date\",\"Time\",\"Pid\",\"Info\",\"Component\",\"Content\",\"EventTemplate\",\"EventId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(data):\n",
    "    data_dict = OrderedDict()\n",
    "    for idx, row in data.iterrows():\n",
    "        blkId_list = re.findall(r'(blk_-?\\d+)', row['Content'])\n",
    "        blkId_set = set(blkId_list)\n",
    "        for blk_Id in blkId_set:\n",
    "            if not blk_Id in data_dict:\n",
    "                data_dict[blk_Id] = []\n",
    "            data_dict[blk_Id].append(row['EventId'])\n",
    "    data_df = pd.DataFrame(list(data_dict.items()), columns=['BlockId', 'EventSequence'])\n",
    "    \n",
    "    return data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_label(df_train_append, label_file):    \n",
    "    label_data =label_file.set_index('BlockId')\n",
    "    label_dict = label_data['Label'].to_dict() \n",
    "    df_train_append['Label'] = df_train_append['BlockId'].apply(lambda x: 1 if label_dict[x] == 'Anomaly' else 0)\n",
    "    return pd.DataFrame(df_train_append)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fo = open(\"abc.txt\", \"r\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_file(fo , charset='utf-8'):\n",
    "#     with open(fo , 'r') as f:\n",
    "#         return f.read().decode(charset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_append = read_file(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_append.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_csv = pd.read_csv('anomaly_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_csv.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# label_data =label_csv.set_index('BlockId')\n",
    "# label_dict = label_data['Label'].to_dict()\n",
    "# label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_append['Label'] = df_train_append['BlockId'].apply(lambda x: 1 if label_dict[x] == 'Anomaly' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_event = pd.DataFrame(df_train_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_event.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train, x_test, y_train, y_test = train_test_split(df_train_append['EventSequence'].values, df_train_append['Label'].values, test_size = 0.2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# from scipy.special import expit\n",
    "# from itertools import compress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_extractor = FeatureExtractor()\n",
    "# x_train = feature_extractor.fit_transform(x_train, term_weighting='tf-idf')\n",
    "# x_test = feature_extractor.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# rfclf = RandomForestClassifier(max_depth=1, random_state=42)\n",
    "# rfclf = rfclf.fit(x_train, y_train)\n",
    "\n",
    "# from sklearn.metrics import f1_score\n",
    "\n",
    "# predicted_y = rfclf.predict(x_test)\n",
    "# print(\"test accuracy: \",f1_score(y_test, predicted_y, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.externals import joblib  \n",
    "\n",
    "# joblib.dump(rfclf, \"trained-model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
